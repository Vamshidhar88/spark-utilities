{"cells":[{"cell_type":"code","source":["from log import syslog, sysError\nimport boto3\n\n\n# Write data to Hive table\ndef write_output_to_hive_table(df_output, target_dir, table_name, mode):\n    try:\n        file_path = table_name.split(\".\")[1]\n        df_output.repartition(1).write.mode(mode).option(\"path\", target_dir + file_path).saveAsTable(table_name)\n        syslog('Successfully written data to hive table : {}'.format(table_name))\n    except Exception as ex:\n        sysError('Failed to write data to hive table : {}'.format(table_name), ex)\n\n\n# Write data to partitioned Hive table\ndef write_output_to_partioned_hive_table(df_output, target_dir, table_name, mode, partition):\n    try:\n        file_path = table_name.split(\".\")[1]\n        df_output.repartition(1).write.mode(mode).partitionBy(partition).option(\"path\",\n                                                                                target_dir + file_path).saveAsTable(\n            table_name)\n        syslog('Successfully written data to hive table : {}'.format(table_name))\n    except Exception as ex:\n        sysError('Failed to write data to hive table : {}'.format(table_name), ex)\n\n\n# write data to hive table with partition given as user input\ndef write_output_to_hive_table_input_partition(df_output, target_dir, table_name, mode, partition):\n    try:\n        file_path = table_name.split(\".\")[1]\n        df_output.repartition(partition).write.mode(mode).option(\"path\",\n                                                                                        target_dir + file_path).saveAsTable(\n            table_name)\n        syslog('Successfully written data to hive table : {}'.format(table_name))\n    except Exception as ex:\n        sysError('Failed to write data to hive table : {}'.format(table_name), ex)\n\n\n# write data to parquet file\ndef write_output_to_parquet(df_output, target_dir, directory_name, mode):\n    try:\n        df_output.repartition(1).write.mode(mode).parquet(target_dir + directory_name)\n        syslog('Successfully written data to target directory as parquet : {}'.format(target_dir + directory_name))\n    except Exception as ex:\n        sysError('Failed to write data to target directory : {}'.format(target_dir + directory_name), ex)\n\n\n# write data to parquet file with partition given as user input\ndef write_output_to_parquet_input_partition(df_output, target_dir, directory_name, mode, partition):\n    try:\n        df_output.repartition(partition).write.mode(mode).parquet(target_dir + directory_name)\n        syslog('Successfully written data to target directory as parquet : {}'.format(directory_name))\n    except Exception as ex:\n        sysError('Failed to write data to target directory : {}'.format(directory_name), ex)\n\n\n# write data to parquet file with partition given as user input and partition by value\ndef write_output_to_parquet_partition_partitionBy(df_output, target_dir, directory_name, mode, partition, partBy):\n    try:\n        df_output.repartition(partition).write.partitionBy(partBy).mode(mode).parquet(target_dir + directory_name)\n        syslog('Successfully written data to target directory as parquet : {}'.format(directory_name))\n    except Exception as ex:\n        sysError('Failed to write data to target directory : {}'.format(directory_name), ex)\n\n\n# write data to plain csv file reading from one s3 bucket and write to other\ndef write_output_to_plain_file_in_s3(pathbucket, input_filepath, ends_with, output_filepath, filename):\n    try:\n        output=output_filepath + filename\n        client = boto3.client('s3')\n        s3 = boto3.resource('s3')\n        bucket = s3.Bucket(pathbucket)\n\n        for obj in bucket.objects.filter(Delimiter='/', Prefix=input_filepath):\n            key = obj.key\n            if key.endswith(ends_with):\n                print(obj.key)\n                client.copy_object(Bucket=pathbucket,\n                                   CopySource=pathbucket + '/' + obj.key,\n                                   Key=output, ServerSideEncryption='aws:kms',\n                                   SSEKMSKeyId='alias/VGI-KMS-S3')\n        syslog('Successfully written file to target directory as plain csv file : {}'.format(output))\n    except Exception as ex:\n        sysError('Failed to write plain file to target directory : {}'.format(output), ex)\n# write to csv file\n# write to csv hive table file\n\n\n#### User this function only when you need Splunk and Email alerts\ndef write_output_to_partioned_hive_table_wtalrt(df_output, target_dir, table_name, mode, partition,alert_var):\n    try:\n        file_path = table_name.split(\".\")[1]\n        df_output.repartition(1).write.mode(mode).partitionBy(partition).option(\"path\",\n                                                                                target_dir + file_path).saveAsTable(\n            table_name)\n        syslog('Successfully written data to hive table : {}'.format(table_name))\n    except Exception as ex:\n        sysError_alert('Failed to write data to hive table : {}'.format(table_name), ex,alert_var)\n\n#### User this function only when you need Splunk and Email alerts\ndef write_output_to_hive_table_with_alert(df_output, target_dir, table_name, mode, alert_var):\n    try:\n        file_path = table_name.split(\".\")[1]\n        df_output.repartition(1).write.mode(mode).option(\"path\", target_dir + file_path).saveAsTable(table_name)\n        syslog('Successfully written data to hive table : {}'.format(table_name))\n    except Exception as ex:\n        sysError('Failed to write data to hive table : {}'.format(table_name), ex, alert_var)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c38ebaff-f588-4ac8-a454-d327d1b18cfd"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"spark_write_utilities","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":842309233682620}},"nbformat":4,"nbformat_minor":0}
